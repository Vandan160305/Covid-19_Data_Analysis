ğŸ¦  COVID-19 Data Analysis Project

ğŸ“Œ Overview

This project demonstrates how to analyze COVID-19 data using Python, Pandas, Matplotlib, and Seaborn.
It covers essential data cleaning, grouping, sorting, filtering, and visualization techniques, along with solving real analytical questions.

ğŸ”§ Functions & Operations Used

import pandas as pd â†’ Import Pandas library

pd.read_csv() â†’ Load CSV file into a DataFrame

df.count() â†’ Count non-null values of each column

df.isnull().sum() â†’ Detect missing values in the DataFrame

import seaborn as sns â†’ Import Seaborn library

import matplotlib.pyplot as plt â†’ Import Matplotlib library

sns.heatmap(df.isnull()) â†’ Visualize missing values in a heatmap

plt.show() â†’ Display the plot

df.groupby('Col_name') â†’ Group data by unique values of a column

df.sort_values(by=['Col_name']) â†’ Sort DataFrame by column values

df[df.Col_1 == 'Element1'] â†’ Filter records where Col_1 has a specific value

â“ Problem Statements

Show the number of Confirmed, Deaths, and Recovered cases in each Region.

Remove all the records where the Confirmed Cases < 10.

Find the Region with the maximum number of Confirmed cases.

Find the Region with the minimum number of Deaths cases.

Show the Confirmed, Deaths, and Recovered cases from India till 29 April 2020.

Sorting:

(A) Sort the data by Confirmed cases (ascending order)

(B) Sort the data by Recovered cases (descending order)

ğŸ“Š Tools & Libraries

Python 3

Pandas â†’ Data manipulation

Matplotlib â†’ Data visualization

Seaborn â†’ Heatmap visualization

Jupyter Notebook â†’ Interactive analysis

ğŸš€ How to Run

Install dependencies:

pip install pandas matplotlib seaborn


Launch Jupyter Notebook:

jupyter notebook


Open the notebook and run the analysis step by step.

âœ… Conclusion

This project highlights the process of cleaning, analyzing, and visualizing COVID-19 datasets.
It provides clear answers to real-world analytical questions, while also demonstrating the power of Python data libraries in handling and exploring datasets effectively.
